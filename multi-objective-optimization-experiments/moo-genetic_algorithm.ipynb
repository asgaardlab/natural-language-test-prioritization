{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af29f3ba-72ba-4cae-9e85-e90ffa89519c",
   "metadata": {},
   "source": [
    "### Multi-objective optimization using NSGA-II for the prioritization of manual test cases in natural language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526d694-1bcc-4e6f-8949-ff4e5eb67602",
   "metadata": {},
   "source": [
    "We performed two main experiments:\n",
    "* **Without feature usage**: our objectives functions are *number of covered features* (maximize) and *test execution time* (minimize)\n",
    "* **With feature usage**: our objectives functions are *number of covered highly-used game features* (maximize) and *test execution time* (minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fdceb8d-3bcd-4a84-8fd2-099fa2d55b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys  \n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from statistics import mean, median\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from cliffs_delta import cliffs_delta\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.problems.functional import FunctionalProblem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.sampling.rnd import PermutationRandomSampling\n",
    "from pymoo.operators.crossover.ox import OrderCrossover\n",
    "from pymoo.operators.mutation.inversion import InversionMutation\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.core.population import Population\n",
    "from pymoo.core.callback import Callback\n",
    "from pymoo.core.termination import Termination\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff8290c-6427-4fb8-a447-910dcb328b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules (py scripts) with needed functions and classes\n",
    "sys.path.insert(0, '/utils')\n",
    "sys.path.insert(0, '/optimization')\n",
    "\n",
    "from utils import utils\n",
    "from optimization import optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c8fff-2dd6-498c-baf3-f742ea34560c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load data: test cases with test labels (covered game features) and execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc87f78-9ca8-4026-a4ab-caff2c56f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_complete = utils.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa997863-c869-4ebb-aaa9-df14c758bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from test cases\n",
    "[feature_coverage_test_suite, execution_time_test_suite, mapping_test_key_test_suite,\n",
    " feature_test_id_relation, total_execution_time_test_suite, number_test_cases] = utils.get_test_data_info(test_cases_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4748f5-8a92-4b22-b5a5-615cb0289633",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_full_suite = []\n",
    "\n",
    "for key,value in feature_coverage_test_suite.items():\n",
    "    for elem in value:\n",
    "        if elem not in features_full_suite:\n",
    "            features_full_suite.append(elem)\n",
    "\n",
    "num_features_full_suite = len(features_full_suite)\n",
    "print(\"There are {num} features being covered in test cases\".format(num=num_features_full_suite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc8a6f-9d7f-4c87-a79d-d425b7e78fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of features tested in each test case\n",
    "num_feat_tested = []\n",
    "\n",
    "for testcase in feature_coverage_test_suite:\n",
    "    num_feat_tested.append(len(feature_coverage_test_suite[testcase]))\n",
    "    \n",
    "print(\"There are {count} features in each test case, on average.\".format(count=mean(num_feat_tested)))\n",
    "print(\"There is a median {count} features in each test case.\".format(count=median(num_feat_tested)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ead56b-0158-4f73-be66-20104d82a70c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get feature usage and basic usage stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cf1d2-19cb-4930-9706-dd5f97899e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read feature usage data (this data was collected from Snowflake at Prodigy and saved with the pickle format)\n",
    "num_uses_features = pd.read_pickle('FEATURE_USAGE_DATA_PATH')\n",
    "print(\"Number of features: {num}\".format(num=len(num_uses_features)))\n",
    "num_uses_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc90e3f-ce12-444a-a4ab-477b6d0b4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mapping (from Snowflake data to testing data)\n",
    "mapping_dict = utils.build_feature_mapping()\n",
    "\n",
    "# Check features that are not in the mapping (e.g., corrupted data from game data events). Use this to check if there is corrupted usage data that needs to be fixed\n",
    "utils.remove_features_mapping(mapping_dict, num_uses_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccaf645-367e-498a-ad0b-ad0bd2e46fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort by usage and get some basic stats\n",
    "num_used_features = num_uses_features.sort_values(by='Number of uses', ascending=False)\n",
    "display(num_used_features.head())\n",
    "\n",
    "most_used_features_test_suite = num_uses_features['Feature'].to_list()\n",
    "print(\"Number of features: {num}\".format(num=len(most_used_features_test_suite)))\n",
    "\n",
    "# Generate boxplot\n",
    "px.box(num_uses_features['Number of uses'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522990b1-bfc6-443d-ae0e-07279ff2d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get median usage and set median_num_features\n",
    "feat_usage_list = num_uses_features['Number of uses'].to_list()\n",
    "\n",
    "median_usage = median(feat_usage_list)\n",
    "counter_feat = 1\n",
    "cum_usage = 0\n",
    "for current_usage in feat_usage_list:\n",
    "    cum_usage += current_usage\n",
    "    if current_usage <= median_usage:\n",
    "        break\n",
    "    counter_feat += 1\n",
    "\n",
    "print(\"Cumulative usage up to median usage: {cum_usage}\".format(cum_usage=cum_usage))\n",
    "\n",
    "cum_median_usage_perc = cum_usage/(sum(feat_usage_list))\n",
    "print(\"Percentage of cumulative usage up to median usage: {cum_median_usage_perc}\".format(cum_median_usage_perc=cum_median_usage_perc))\n",
    "print(\"Corresponding number of features up to median usage: {median_num_features}\".format(median_num_features=counter_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a69b887c-e7fe-4eef-9822-b03513f2ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature names from game data in Snowflake to standard names in the testing side\n",
    "most_used_features_test_suite_testing_std = [mapping_dict[x] for x in most_used_features_test_suite] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d620d-1fd0-42d9-8f74-a788041bf53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some game data events lead to the same testing feature (i.e., there are duplicates in most_used_features_test_suite_testing_std). Below, we remove them keeping the first\n",
    "most_used_features_test_suite_testing_std = list(dict.fromkeys(most_used_features_test_suite_testing_std))\n",
    "print(\"Now there are {num} features in the set of most used features\".format(num=len(most_used_features_test_suite_testing_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a437028-34bd-486d-9ee9-56988bb5e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with ranking position of the most used features\n",
    "most_used_features_rank = {}\n",
    "counter = 1\n",
    "for feat in most_used_features_test_suite_testing_std:\n",
    "    most_used_features_rank[feat] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf0bdf0d-1874-444d-b0fe-4792f11eea09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get num. of times each feature is covered (i.e., number of test cases where each feature appears)\n",
    "feature_counter = {}\n",
    "for key,value in feature_coverage_test_suite.items():\n",
    "    for feat in value:\n",
    "        if feat not in feature_counter:\n",
    "            feature_counter[feat] = 1\n",
    "        else:\n",
    "            feature_counter[feat] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a4f64-0904-42a5-b89d-fa3db5edef99",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define objective/fitness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd7ccf2-c02e-466e-9bd2-1cb2d1c8b966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute cumulative feature coverage for a specific test execution order and feature per-feature coverage threshold\n",
    "def get_cum_feature_coverage_test_suite(order, feature_counter, thresh):\n",
    "    cum_feature_count = 0\n",
    "    cum_feature_count_array = []\n",
    "    features_covered = []\n",
    "    feature_counter_order = dict.fromkeys(feature_counter.keys(),0)\n",
    "\n",
    "    for test_case_id in order:\n",
    "        features = feature_coverage_test_suite[test_case_id]\n",
    "\n",
    "        # Update dict with counter\n",
    "        for feat in features:\n",
    "            feature_counter_order[feat] = feature_counter_order[feat] + 1\n",
    "            \n",
    "            # Check if feature meets threshold to be considered covered\n",
    "            if feature_counter_order[feat] >= math.floor(feature_counter[feat]*thresh):\n",
    "                if feat not in features_covered:\n",
    "                    features_covered.append(feat)\n",
    "                    cum_feature_count = cum_feature_count + 1\n",
    "\n",
    "        cum_feature_count_array.append(cum_feature_count)\n",
    "\n",
    "    # Define arrays for test case (X axis) versus cumulative feature count (Y axis)\n",
    "    x = np.array([i for i in range(len(order))])\n",
    "    y = cum_feature_count_array\n",
    "    \n",
    "    # Compute area using trapezoidal rule\n",
    "    area = np.trapz(y=y, x=x)\n",
    "    \n",
    "    # Compute optimal area\n",
    "    optimal_area = np.trapz(y=np.array([num_features_full_suite]*len(x)), x=x)\n",
    "\n",
    "    # Normalize area\n",
    "    norm_area = area/optimal_area\n",
    "\n",
    "    return norm_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc747e4-3c1d-415d-ba67-f08cb6df42c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute cumulative execution time for a specific test execution order\n",
    "def get_cum_execution_time_test_suite(order):\n",
    "    cum_execution_time = 0\n",
    "    cum_execution_time_array = []\n",
    "\n",
    "    for test_case_id in order:\n",
    "        exec_time = execution_time_test_suite[test_case_id]\n",
    "        cum_execution_time = cum_execution_time + exec_time\n",
    "        cum_execution_time_array.append(cum_execution_time)\n",
    "        \n",
    "    x = np.array([i for i in range(len(order))])\n",
    "    y = cum_execution_time_array\n",
    "    \n",
    "    # Compute area using trapezoidal rule\n",
    "    area = np.trapz(y=y, x=x)\n",
    "\n",
    "    # Compute optimal area\n",
    "    optimal_area = np.trapz(y=np.array([total_execution_time_test_suite]*len(x)), x=x)\n",
    "    \n",
    "    # Normalize area\n",
    "    norm_area = area/optimal_area\n",
    "\n",
    "    return norm_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718483c1-084f-452e-b327-ae490b0c3b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute ranking similarity score for a specific test execution order using 'feature usage' as relevance for features\n",
    "def get_ranking_score_full_suite(order, true_relev, scaler_ndcg):\n",
    "    global most_used_features_rank\n",
    "    \n",
    "    list_tested_features = []\n",
    "    \n",
    "    for test_case_id in order:\n",
    "        features = feature_coverage_test_suite_reduced[test_case_id] \n",
    "        for feat in features:\n",
    "                \n",
    "            if feat not in list_tested_features:\n",
    "                list_tested_features.append(feat)\n",
    "        \n",
    "    tested_feat_relev = {}\n",
    "    for feat in list_tested_features:\n",
    "        # Use usage ranking to find relevance for the currently tested feature\n",
    "        tested_feat_relev[feat] = most_used_features_rank[feat]\n",
    "\n",
    "    score_relev = list(tested_feat_relev.values())\n",
    "    \n",
    "    # Compute NDCG\n",
    "    score = ndcg_score(np.asarray([true_relev]),np.asarray([score_relev]))\n",
    "    scaled_score = scaler_ndcg.transform(np.asarray(score).reshape(-1, 1))[0][0]\n",
    "    return scaled_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb8e5b6-2749-4b92-8932-0106434d1175",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Modify NSGA-II to use T-test and mutual dominance rate as stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e64a1f3-709c-47eb-bdad-e883ee2f0ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using callback and custom termination criteria\n",
    "class MyCallback(Callback):\n",
    "    \n",
    "    def __init__(self, mdr_limit) -> None:\n",
    "        super().__init__()\n",
    "        self.data[\"terminate\"] = False\n",
    "        self.data[\"index\"] = 0\n",
    "        self.data[\"last_gen_solution\"] = []\n",
    "        self.data[\"current_gen_solution\"] = []\n",
    "        self.data[\"last_gen_objectives\"] = []\n",
    "        self.data[\"current_gen_objectives\"] = []\n",
    "        self.data[\"last_gen_t_test\"] = False\n",
    "        self.data[\"current_gen_t_test\"] = False\n",
    "        self.data[\"count_last_mdr\"] = 0\n",
    "        self.data[\"count_last_t_test\"] = 0\n",
    "        self.data[\"MDR_LIMIT\"] = mdr_limit\n",
    "        \n",
    "    def get_mutual_dom_rate(self, gen_1_obj, gen_2_obj):\n",
    "        counter = 0\n",
    "        found = False\n",
    "        for obj_values_gen_1 in gen_1_obj:\n",
    "            for obj_values_gen_2 in gen_2_obj:\n",
    "                if not found:\n",
    "                    if all(obj_values_gen_2[index] >= obj_values_gen_1[index] for index in range(len(obj_values_gen_2))):\n",
    "                        if any(obj_values_gen_2[index] > obj_values_gen_1[index] for index in range(len(obj_values_gen_2))):\n",
    "                            counter += 1\n",
    "                            found = True\n",
    "            found = False\n",
    "            \n",
    "        return counter\n",
    "\n",
    "    def notify(self, algorithm):\n",
    "\n",
    "        if self.data[\"index\"] == 0:\n",
    "            self.data[\"last_gen_solution\"] = algorithm.opt\n",
    "            self.data[\"index\"] = 1\n",
    "            obj_results = algorithm.opt.get(\"F\").T\n",
    "            self.data[\"last_gen_objectives\"] = obj_results\n",
    "\n",
    "        else:\n",
    "            self.data[\"current_gen_solution\"] = algorithm.opt\n",
    "            \n",
    "            # Transpose objective results and iterate through results for all objectives\n",
    "            obj_results = algorithm.opt.get(\"F\").T\n",
    "            self.data[\"current_gen_objectives\"] = obj_results\n",
    "\n",
    "            # Compute t-test for each objective\n",
    "            t_test_res_list = []\n",
    "            for index in range(len(self.data[\"current_gen_objectives\"])):\n",
    "                single_obj_values_current = self.data[\"current_gen_objectives\"][index]\n",
    "                single_obj_values_last = self.data[\"last_gen_objectives\"][index]\n",
    "                t_test_res = stats.ttest_ind(single_obj_values_current, single_obj_values_last)[1] # get only p-value\n",
    "                t_test_res_list.append(t_test_res)\n",
    "            \n",
    "            # Get mutual dominance rates\n",
    "            dom_last_current = self.get_mutual_dom_rate(self.data[\"last_gen_objectives\"].T, self.data[\"current_gen_objectives\"].T)\n",
    "            dom_current_last = self.get_mutual_dom_rate(self.data[\"current_gen_objectives\"].T, self.data[\"last_gen_objectives\"].T)\n",
    "            mdr = (dom_last_current/len(self.data[\"last_gen_objectives\"].T)) - (dom_current_last/len(self.data[\"current_gen_objectives\"].T))\n",
    "            \n",
    "            # Check is mdr is within range and increase counter; otherwise, reset counter\n",
    "            if abs(mdr) < self.data[\"MDR_LIMIT\"]:\n",
    "                self.data[\"count_last_mdr\"] += 1\n",
    "            else:\n",
    "                self.data[\"count_last_mdr\"] = 0\n",
    "                \n",
    "            # Check is t-test for all objectives is above 0.05 and increase counter; otherwise, reset counter\n",
    "            if all(i > 0.05 for i in t_test_res_list):\n",
    "                self.data[\"count_last_t_test\"] += 1\n",
    "            else:\n",
    "                self.data[\"count_last_t_test\"] = 0\n",
    "                \n",
    "            # Check if mdr and t-test meet criteria for 5 generations\n",
    "            if (self.data[\"count_last_mdr\"] >= 5) and (self.data[\"count_last_t_test\"] >= 5):\n",
    "                self.data[\"terminate\"] = True\n",
    "\n",
    "            # Update last generation\n",
    "            self.data[\"last_gen_solution\"] = self.data[\"current_gen_solution\"]\n",
    "            self.data[\"last_gen_objectives\"] = self.data[\"current_gen_objectives\"]\n",
    "            self.data[\"last_gen_t_test\"] = self.data[\"current_gen_t_test\"]\n",
    "            self.data[\"last_gen_mdr\"] = mdr\n",
    "\n",
    "\n",
    "class MyTermination(Termination):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "    def terminate(self):\n",
    "        self.force_termination = True\n",
    "   \n",
    "    def update(self, algorithm):\n",
    "        \"\"\"\n",
    "        Provide the termination criterion a current status of the algorithm to update the perc.\n",
    "        Parameters\n",
    "        ----------\n",
    "        algorithm : object\n",
    "            The algorithm object which is used to determine whether a run has terminated.\n",
    "        \"\"\"\n",
    "        \n",
    "        if my_callback.data[\"terminate\"]:\n",
    "            self.terminate()\n",
    "        \n",
    "        if self.force_termination:\n",
    "            progress = 1.0\n",
    "        else:\n",
    "            progress = self._update(algorithm)\n",
    "            assert progress >= 0.0\n",
    "\n",
    "        self.perc = progress\n",
    "        return self.perc\n",
    "    \n",
    "    def _update(self, algorithm):\n",
    "        return 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f094f7-4823-4549-b931-7bd6f230150f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe0a648-2c06-4e74-8622-08adc5819947",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Experiment 1 (without feature usage) - execute optimization 50 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb00e9-1899-4cb1-8f9f-0d0e444f2841",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Per-feature threshold of 50%\n",
    "thresh = 0.50\n",
    "results_50_exec_thresh_50 = pd.DataFrame(columns=['feat_cov', 'exec_time', 'approach'])\n",
    "index_add = 0\n",
    "\n",
    "# MDR 0.05\n",
    "mdr_range = 0.05\n",
    "results_50_exec_thresh_50_005_list = []\n",
    "\n",
    "for index in range(50):\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_50_005_list.append(results_temp)\n",
    "\n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_50.loc[index_add] = list(res) + ['Stop_005']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.10\n",
    "mdr_range = 0.10\n",
    "results_50_exec_thresh_50_010_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_50_010_list.append(results_temp)\n",
    "\n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_50.loc[index_add] = list(res) + ['Stop_010']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.25\n",
    "mdr_range = 0.25\n",
    "results_50_exec_thresh_50_025_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "\n",
    "    results_50_exec_thresh_50_025_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_50.loc[index_add] = list(res) + ['Stop_025']\n",
    "        index_add += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb99fa7-0538-4250-98cc-1e9ba931968a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Per-feature threshold of 75%\n",
    "thresh = 0.75\n",
    "results_50_exec_thresh_75 = pd.DataFrame(columns=['feat_cov', 'exec_time', 'approach'])\n",
    "index_add = 0\n",
    "\n",
    "# MDR 0.05\n",
    "mdr_range = 0.05\n",
    "results_50_exec_thresh_75_005_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_75_005_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_75.loc[index_add] = list(res) + ['Stop_005']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.10\n",
    "mdr_range = 0.10\n",
    "results_50_exec_thresh_75_010_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_75_010_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_75.loc[index_add] = list(res) + ['Stop_010']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.25\n",
    "mdr_range = 0.25\n",
    "results_50_exec_thresh_75_025_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_75_025_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_75.loc[index_add] = list(res) + ['Stop_025']\n",
    "        index_add += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f53263-7346-49ee-9d31-7389313b852a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Per-feature threshold of 90%\n",
    "thresh = 0.90\n",
    "results_50_exec_thresh_90 = pd.DataFrame(columns=['feat_cov', 'exec_time', 'approach'])\n",
    "index_add = 0\n",
    "\n",
    "# MDR 0.05\n",
    "mdr_range = 0.05\n",
    "results_50_exec_thresh_90_005_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_90_005_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_90.loc[index_add] = list(res) + ['Stop_005']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.10\n",
    "mdr_range = 0.10\n",
    "results_50_exec_thresh_90_010_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_90_010_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_90.loc[index_add] = list(res) + ['Stop_010']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.25\n",
    "mdr_range = 0.25\n",
    "results_50_exec_thresh_90_025_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_90_025_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_90.loc[index_add] = list(res) + ['Stop_025']\n",
    "        index_add += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9109f59-2807-41b9-adb7-56fab768ef9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Per-feature threshold of 100%\n",
    "thresh = 1\n",
    "results_50_exec_thresh_100 = pd.DataFrame(columns=['feat_cov', 'exec_time', 'approach'])\n",
    "index_add = 0\n",
    "\n",
    "# MDR 0.05\n",
    "mdr_range = 0.05\n",
    "results_50_exec_thresh_100_005_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_100_005_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_100.loc[index_add] = list(res) + ['Stop_005']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.10\n",
    "mdr_range = 0.10\n",
    "results_50_exec_thresh_100_010_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_100_010_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_100.loc[index_add] = list(res) + ['Stop_010']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.25\n",
    "mdr_range = 0.25\n",
    "results_50_exec_thresh_100_025_list = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_cum_feature_coverage_full_suite(x, feature_counter, thresh),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_100_025_list.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_100.loc[index_add] = list(res) + ['Stop_025']\n",
    "        index_add += 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a0219-ff11-4af8-b6b6-7a8e4a85fba2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Experiment 2 (with feature usage) - execute optimization 50 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80933539-544a-44ac-be12-a7b040e666f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimal relevance (true relevance) and its inverse (worse relevance) to normalize DCG\n",
    "true_relev = list(most_used_features_rank.values())\n",
    "worst_relev = true_relev.copy()\n",
    "worst_relev.reverse()\n",
    "\n",
    "# Get min and max scores (NDCG) and fit scaler\n",
    "scaler_ndcg = MinMaxScaler()\n",
    "max_score_ndcg = ndcg_score(np.asarray([true_relev]),np.asarray([true_relev]))\n",
    "min_score_ndcg = ndcg_score(np.asarray([true_relev]),np.asarray([worst_relev]))\n",
    "scaler_ndcg.fit(np.asarray([min_score_ndcg, max_score_ndcg]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060df3e0-114d-428c-9a58-33a474b23600",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_50_exec_thresh_50_exp_2 = pd.DataFrame(columns=['feat_usage', 'exec_time', 'approach'])\n",
    "index_add = 0\n",
    "\n",
    "# MDR 0.05\n",
    "mdr_range = 0.05\n",
    "results_50_exec_thresh_50_005_list_exp_2 = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_ranking_score_full_suite(x, true_relev, scaler_ndcg),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_50_005_list_exp_2.append(results_temp)\n",
    "\n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_50_exp_2.loc[index_add] = list(res) + ['Stop_005']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.10\n",
    "mdr_range = 0.10\n",
    "results_50_exec_thresh_50_010_list_exp_2 = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_ranking_score_full_suite(x, true_relev, scaler_ndcg),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "    \n",
    "    results_50_exec_thresh_50_010_list_exp_2.append(results_temp)\n",
    "\n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_50_exp_2.loc[index_add] = list(res) + ['Stop_010']\n",
    "        index_add += 1\n",
    "        \n",
    "\n",
    "# MDR 0.25\n",
    "mdr_range = 0.25\n",
    "results_50_exec_thresh_50_025_list_exp_2 = []\n",
    "\n",
    "for index in range(50):\n",
    "\n",
    "    my_callback = MyCallback(mdr_range)\n",
    "    my_termination = MyTermination()\n",
    "\n",
    "    # Multiply by (-1) because we want to solve a maximization problem (by pymoo only has minimization)\n",
    "    objs = [\n",
    "        lambda x: (-1)*get_ranking_score_full_suite(x, true_relev, scaler_ndcg),\n",
    "        lambda x: get_cum_execution_time_full_suite(x)\n",
    "    ]\n",
    "\n",
    "    n_var = index_test_case\n",
    "    problem = FunctionalProblem(n_var, objs, xl=0, xu=(index_test_case-1), vtype=int)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                     sampling=PermutationRandomSampling(),\n",
    "                     mutation=InversionMutation(),\n",
    "                     crossover=OrderCrossover(),\n",
    "                     eliminate_duplicates=True)\n",
    "    # Run optimization\n",
    "    results_temp = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=algorithm,\n",
    "        termination=my_termination,\n",
    "        callback=my_callback)\n",
    "\n",
    "    results_50_exec_thresh_50_025_list_exp_2.append(results_temp)\n",
    "    \n",
    "    for res in results_temp.F:\n",
    "        results_50_exec_thresh_50_exp_2.loc[index_add] = list(res) + ['Stop_025']\n",
    "        index_add += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370fd85c-b712-4414-b6b9-3eb8d6d2e800",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Random-search based approach - execute optimization 50 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb2a43-17f8-4146-9211-d3a805467845",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_50_executions_random_50 = []\n",
    "results_50_executions_random_100 = []\n",
    "\n",
    "# Get random solution (50 and 100)\n",
    "for i in range(50):\n",
    "    random_50_list = []\n",
    "    for j in range(50):\n",
    "        generated_perm = np.random.permutation(list(range(index_test_case)))\n",
    "        random_50_list.append(generated_perm)\n",
    "    results_50_executions_random_50.append(random_50_list)\n",
    "\n",
    "for i in range(50):\n",
    "    random_100_list = []\n",
    "    for j in range(100):\n",
    "        generated_perm = np.random.permutation(list(range(index_test_case)))\n",
    "        random_100_list.append(generated_perm)\n",
    "    results_50_executions_random_100.append(random_100_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e9df2-30de-41d5-81a5-e10de751f567",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Functions to plot optimal results later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da500957-9f86-4879-b052-c34147a2a475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cum_perc_feature_coverage(order, feature_counter, thresh):\n",
    "    cum_feature_count = 0\n",
    "    cum_feature_count_array = []\n",
    "    features_covered = []\n",
    "    \n",
    "    feature_counter_order = dict.fromkeys(feature_counter.keys(),0)\n",
    "    \n",
    "    for test_case_id in order:\n",
    "        features = feature_coverage_full_suite[test_case_id]\n",
    "        # Update dict with counter\n",
    "        for feat in features:\n",
    "            feature_counter_order[feat] = feature_counter_order[feat] + 1\n",
    "\n",
    "        for feat in feature_counter_order:\n",
    "            if feature_counter_order[feat] >= math.floor(feature_counter[feat]*thresh):\n",
    "                if feat not in features_covered:\n",
    "                    features_covered.append(feat)\n",
    "                    cum_feature_count = cum_feature_count + 1\n",
    "\n",
    "        cum_feature_count_array.append(cum_feature_count)\n",
    "    \n",
    "    cum_feature_count_array = np.array(cum_feature_count_array)\n",
    "    percent_cum_feature_count = (cum_feature_count_array/num_features_full_suite)*100\n",
    "    \n",
    "    return percent_cum_feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef25a1fc-4486-4ec5-b2a4-d99e58e5749e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cum_perc_execution_time(order):\n",
    "    cum_execution_time = 0\n",
    "    cum_execution_time_array = []\n",
    "    \n",
    "    for test_case_id in order:\n",
    "        exec_time = execution_time_full_suite[test_case_id]\n",
    "        cum_execution_time = cum_execution_time + exec_time\n",
    "        cum_execution_time_array.append(cum_execution_time)\n",
    "\n",
    "    cum_execution_time_array = np.array(cum_execution_time_array)\n",
    "    \n",
    "    return cum_execution_time_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4aa2fd-4b48-4ea5-9dcd-a7b999ff7978",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Functions to compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59097e99-799a-402e-8416-67b2777b141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cum_perc_feature_coverage(order, feature_counter, thresh):\n",
    "    cum_feature_count = 0\n",
    "    cum_feature_count_array = []\n",
    "    features_covered = []\n",
    "    \n",
    "    feature_counter_order = dict.fromkeys(feature_counter.keys(),0)\n",
    "    \n",
    "    for test_case_id in order:\n",
    "        features = feature_coverage_full_suite[test_case_id]\n",
    "\n",
    "        # Update dict with counter\n",
    "        for feat in features:\n",
    "            feature_counter_order[feat] = feature_counter_order[feat] + 1\n",
    "            \n",
    "            if feature_counter_order[feat] >= math.floor(feature_counter[feat]*thresh):\n",
    "                if feat not in features_covered:\n",
    "                    features_covered.append(feat)\n",
    "                    cum_feature_count = cum_feature_count + 1\n",
    "\n",
    "        cum_feature_count_array.append(cum_feature_count)\n",
    "        \n",
    "    cum_feature_count_array = np.array(cum_feature_count_array)\n",
    "    percent_cum_feature_count = (cum_feature_count_array/num_features_full_suite)*100\n",
    "    \n",
    "    return percent_cum_feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9cac602-b8d2-481d-a6f0-4704e9fb8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cum_perc_execution_time(order):\n",
    "    cum_execution_time = 0\n",
    "    cum_execution_time_array = []\n",
    "    \n",
    "    for test_case_id in order:\n",
    "        exec_time = execution_time_full_suite[test_case_id]\n",
    "        cum_execution_time = cum_execution_time + exec_time\n",
    "        cum_execution_time_array.append(cum_execution_time)\n",
    "\n",
    "    cum_execution_time_array = np.array(cum_execution_time_array)\n",
    "    \n",
    "    return cum_execution_time_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d814479e-c271-4d99-a235-18701a256e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cum_perc_most_used_feat_cov(order, feature_counter, thresh_coverage, most_used_features_test_suite_testing_std, top_k):\n",
    "    cum_top_k_covered_count = 0\n",
    "    cum_top_k_covered_count_array = []\n",
    "    top_k_covered = []\n",
    "    feature_counter_order = dict.fromkeys(feature_counter.keys(),0)\n",
    "    \n",
    "    top_k_len = round(len(most_used_features_test_suite_testing_std)*top_k)\n",
    "    top_k_most_used = most_used_features_test_suite_testing_std[:top_k_len]\n",
    "    \n",
    "    for test_case_id in order:\n",
    "        features = feature_coverage_test_suite[test_case_id]\n",
    "        inters_features = set(features).intersection(set(top_k_most_used))\n",
    "        \n",
    "        for feat in inters_features:\n",
    "            if feat not in top_k_covered:\n",
    "                top_k_covered.append(feat)\n",
    "                cum_top_k_covered_count += 1\n",
    "        \n",
    "        cum_top_k_covered_count_array.append(cum_top_k_covered_count)\n",
    "    \n",
    "    cum_top_k_covered_count_array = np.array(cum_top_k_covered_count_array)\n",
    "    percent_cum_top_k_covered_count_array = (cum_top_k_covered_count_array/top_k_len)*100\n",
    "    \n",
    "    return percent_cum_top_k_covered_count_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295904bf-f2e1-4fcc-9e6c-d024d354f63d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6335cd-08f1-4719-83e5-d94d2e73ed84",
   "metadata": {},
   "source": [
    "### Results of experiment 1 - optimization without feature usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe9528-2eeb-4641-87c4-c3816e5e73fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Basic stats of optimal solutions - Number of optimal solutions found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "333a7e01-d65b-482f-9d5b-bb0643e127a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 53.0 solutions for MDR within 0.05 and 50% per-feat.cov.\n",
      "There are 48.5 solutions for MDR within 0.05 and 75% per-feat.cov.\n",
      "There are 60.0 solutions for MDR within 0.05 and 90% per-feat.cov.\n",
      "There are 65.0 solutions for MDR within 0.05 and 100% per-feat.cov.\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.05\n",
    "print(\"There are {count} solutions for MDR within 0.05 and 50% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_50_005_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.05 and 75% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_75_005_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.05 and 90% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_90_005_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.05 and 100% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_100_005_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b047d7b5-231d-40cc-9189-e8e1a174b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34.5 solutions for MDR within 0.1 and 50% per-feat.cov.\n",
      "There are 33.5 solutions for MDR within 0.1 and 75% per-feat.cov.\n",
      "There are 32.0 solutions for MDR within 0.1 and 90% per-feat.cov.\n",
      "There are 35.5 solutions for MDR within 0.1 and 100% per-feat.cov.\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.10\n",
    "print(\"There are {count} solutions for MDR within 0.1 and 50% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_50_010_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.1 and 75% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_75_010_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.1 and 90% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_90_010_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.1 and 100% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_100_010_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de048e98-fff4-4273-8e95-328fcf52ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17.5 solutions for MDR within 0.25 and 50% per-feat.cov.\n",
      "There are 18.0 solutions for MDR within 0.25 and 75% per-feat.cov.\n",
      "There are 18.5 solutions for MDR within 0.25 and 90% per-feat.cov.\n",
      "There are 18.0 solutions for MDR within 0.25 and 100% per-feat.cov.\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.25\n",
    "print(\"There are {count} solutions for MDR within 0.25 and 50% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_50_025_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.25 and 75% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_75_025_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.25 and 90% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_90_025_list])))\n",
    "print(\"There are {count} solutions for MDR within 0.25 and 100% per-feat.cov.\".format(count=median([len(x.opt) for x in results_50_exec_thresh_100_025_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3c6d5c4-a7ef-4c3f-b5a8-7a9218c32611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34.5 solutions for 50% per-feat.cov. threshold.\n",
      "There are 33.5 solutions for 75% per-feat.cov. threshold.\n",
      "There are 32.0 solutions for 90% per-feat.cov. threshold.\n",
      "There are 35.5 solutions for 100% per-feat.cov. threshold.\n"
     ]
    }
   ],
   "source": [
    "# Median number of optimal solutions for each per-feat.cov. threshold\n",
    "print(\"There are {count} solutions for 50% per-feat.cov. threshold.\".format(count=median([median([len(x.opt) for x in results_50_exec_thresh_50_005_list]),\n",
    "                                                                                          median([len(x.opt) for x in results_50_exec_thresh_50_010_list]),\n",
    "                                                                                          median([len(x.opt) for x in results_50_exec_thresh_50_025_list])])))\n",
    "\n",
    "print(\"There are {count} solutions for 75% per-feat.cov. threshold.\".format(count=median([median([len(x.opt) for x in results_50_exec_thresh_75_005_list]),\n",
    "                                                                                          median([len(x.opt) for x in results_50_exec_thresh_75_010_list]),\n",
    "                                                                                          median([len(x.opt) for x in results_50_exec_thresh_75_025_list])])))\n",
    "\n",
    "print(\"There are {count} solutions for 90% per-feat.cov. threshold.\".format(count=median([median([len(x.opt) for x in results_50_exec_thresh_90_005_list]),\n",
    "                                                                                          median([len(x.opt) for x in results_50_exec_thresh_90_010_list]),\n",
    "                                                                                          median([len(x.opt) for x in results_50_exec_thresh_90_025_list])])))\n",
    "\n",
    "print(\"There are {count} solutions for 100% per-feat.cov. threshold.\".format(count=median([median([len(x.opt) for x in results_50_exec_thresh_100_005_list]),\n",
    "                                                                                          median([len(x.opt) for x in results_50_exec_thresh_100_010_list]),\n",
    "                                                                                          median([len(x.opt) for x in results_50_exec_thresh_100_025_list])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "8618cda1-4cb6-4677-b3a4-82bfd68fd409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18.0 solutions for MDR within 0.25.\n",
      "There are 34.0 solutions for MDR within 0.10.\n",
      "There are 56.5 solutions for MDR within 0.05.\n"
     ]
    }
   ],
   "source": [
    "# Median number of optimal solutions for each MDR range\n",
    "print(\"There are {count} solutions for MDR within 0.25.\".format(count=median([median([len(x.opt) for x in results_50_exec_thresh_50_025_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_75_025_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_90_025_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_100_025_list])])))\n",
    "\n",
    "print(\"There are {count} solutions for MDR within 0.10.\".format(count=median([median([len(x.opt) for x in results_50_exec_thresh_50_010_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_75_010_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_90_010_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_100_010_list])])))\n",
    "\n",
    "print(\"There are {count} solutions for MDR within 0.05.\".format(count=median([median([len(x.opt) for x in results_50_exec_thresh_50_005_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_75_005_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_90_005_list]),\n",
    "                                                                              median([len(x.opt) for x in results_50_exec_thresh_100_005_list])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2912f-3e51-442c-bdec-a15b4ebdf79c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Basic stats of optimal solutions - Number of fitness evaluations to find optimal solutions found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ec49807-0a0a-4b9c-bdc3-887be349fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 33000.0 fitness eval. for MDR within 0.05 and 50% per-feat.cov.\n",
      "There were 36700.0 fitness eval. for MDR within 0.05 and 75% per-feat.cov.\n",
      "There were 45000.0 fitness eval. for MDR within 0.05 and 90% per-feat.cov.\n",
      "There were 39200.0 fitness eval. for MDR within 0.05 and 100% per-feat.cov.\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.05\n",
    "print(\"There were {count} fitness eval. for MDR within 0.05 and 50% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_005_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.05 and 75% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_005_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.05 and 90% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_005_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.05 and 100% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_005_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ed250c2-b328-443e-9153-60846bcbbd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 17150.0 fitness eval. for MDR within 0.1 and 50% per-feat.cov.\n",
      "There were 13750.0 fitness eval. for MDR within 0.1 and 75% per-feat.cov.\n",
      "There were 15350.0 fitness eval. for MDR within 0.1 and 90% per-feat.cov.\n",
      "There were 15250.0 fitness eval. for MDR within 0.1 and 100% per-feat.cov.\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.10\n",
    "print(\"There were {count} fitness eval. for MDR within 0.1 and 50% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_010_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.1 and 75% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_010_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.1 and 90% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_010_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.1 and 100% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_010_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab88652f-7db9-4cbb-a2cf-c0ab501c4318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 3700.0 fitness eval. for MDR within 0.25 and 50% per-feat.cov.\n",
      "There were 3800.0 fitness eval. for MDR within 0.25 and 75% per-feat.cov.\n",
      "There were 3500.0 fitness eval. for MDR within 0.25 and 90% per-feat.cov.\n",
      "There were 3250.0 fitness eval. for MDR within 0.25 and 100% per-feat.cov.\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.25\n",
    "print(\"There were {count} fitness eval. for MDR within 0.25 and 50% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_025_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.25 and 75% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_025_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.25 and 90% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_025_list])))\n",
    "print(\"There were {count} fitness eval. for MDR within 0.25 and 100% per-feat.cov.\".format(count=median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_025_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0d3b283-7685-4404-809e-fc94906c1a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 17150.0 fitness eval. for 50% per-feat.cov. threshold.\n",
      "There were 13750.0 fitness eval. for 75% per-feat.cov. threshold.\n",
      "There were 15350.0 fitness eval. for 90% per-feat.cov. threshold.\n",
      "There were 15250.0 fitness eval. for 100% per-feat.cov. threshold.\n"
     ]
    }
   ],
   "source": [
    "# Median number of optimal solutions for each per-feat.cov. threshold\n",
    "print(\"There were {count} fitness eval. for 50% per-feat.cov. threshold.\".format(count=median([median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_005_list]),\n",
    "                                                                                               median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_010_list]),\n",
    "                                                                                               median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_025_list])])))\n",
    "\n",
    "print(\"There were {count} fitness eval. for 75% per-feat.cov. threshold.\".format(count=median([median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_005_list]),\n",
    "                                                                                               median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_010_list]),\n",
    "                                                                                               median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_025_list])])))\n",
    "\n",
    "print(\"There were {count} fitness eval. for 90% per-feat.cov. threshold.\".format(count=median([median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_005_list]),\n",
    "                                                                                               median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_010_list]),\n",
    "                                                                                               median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_025_list])])))\n",
    "\n",
    "print(\"There were {count} fitness eval. for 100% per-feat.cov. threshold.\".format(count=median([median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_005_list]),\n",
    "                                                                                               median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_010_list]),\n",
    "                                                                                               median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_025_list])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "ef8b2e15-7cb5-4940-9fd4-af047da396ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 3600.0 fitness eval. for MDR within 0.25.\n",
      "There were 15300.0 fitness eval. for MDR within 0.10.\n",
      "There were 37950.0 fitness eval. for MDR within 0.05.\n"
     ]
    }
   ],
   "source": [
    "# Median number of fitness evaluations for each MDR range\n",
    "print(\"There were {count} fitness eval. for MDR within 0.25.\".format(count=median([median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_025_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_025_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_025_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_025_list])])))\n",
    "\n",
    "print(\"There were {count} fitness eval. for MDR within 0.10.\".format(count=median([median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_010_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_010_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_010_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_010_list])])))\n",
    "\n",
    "print(\"There were {count} fitness eval. for MDR within 0.05.\".format(count=median([median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_50_005_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_75_005_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_90_005_list]),\n",
    "                                                                                   median([x.algorithm.evaluator.n_eval for x in results_50_exec_thresh_100_005_list])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f840fdc-6f4b-4981-a0f7-c2dcbcaf6450",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Basic stats of optimal solutions - Execution time to find optimal solutions found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fcd3831c-887f-4b3d-9273-aac91f645524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time to find solutions for MDR within 0.05 and 50% per-feat.cov. is: 86.8531 seconds\n",
      "Execution time to find solutions for MDR within 0.05 and 75% per-feat.cov. is: 85.1016 seconds\n",
      "Execution time to find solutions for MDR within 0.05 and 90% per-feat.cov. is: 95.4464 seconds\n",
      "Execution time to find solutions for MDR within 0.05 and 100% per-feat.cov. is: 78.3439 seconds\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.05\n",
    "print(\"Execution time to find solutions for MDR within 0.05 and 50% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_50_005_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.05 and 75% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_75_005_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.05 and 90% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_90_005_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.05 and 100% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_100_005_list]), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f442738-4759-41df-8537-9c7d01e1e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time to find solutions for MDR within 0.1 and 50% per-feat.cov. is: 44.6449 seconds\n",
      "Execution time to find solutions for MDR within 0.1 and 75% per-feat.cov. is: 31.7567 seconds\n",
      "Execution time to find solutions for MDR within 0.1 and 90% per-feat.cov. is: 32.4744 seconds\n",
      "Execution time to find solutions for MDR within 0.1 and 100% per-feat.cov. is: 30.3925 seconds\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.10\n",
    "print(\"Execution time to find solutions for MDR within 0.1 and 50% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_50_010_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.1 and 75% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_75_010_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.1 and 90% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_90_010_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.1 and 100% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_100_010_list]), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b2de153-e6a1-4368-a060-75e7d0e43a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time to find solutions for MDR within 0.25 and 50% per-feat.cov. is: 9.5058 seconds\n",
      "Execution time to find solutions for MDR within 0.25 and 75% per-feat.cov. is: 8.6875 seconds\n",
      "Execution time to find solutions for MDR within 0.25 and 90% per-feat.cov. is: 7.4244 seconds\n",
      "Execution time to find solutions for MDR within 0.25 and 100% per-feat.cov. is: 6.4418 seconds\n"
     ]
    }
   ],
   "source": [
    "# MDR within 0.25\n",
    "print(\"Execution time to find solutions for MDR within 0.25 and 50% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_50_025_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.25 and 75% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_75_025_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.25 and 90% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_90_025_list]), 4)))\n",
    "print(\"Execution time to find solutions for MDR within 0.25 and 100% per-feat.cov. is: {count} seconds\".format(count=round(median([x.exec_time for x in results_50_exec_thresh_100_025_list]), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fdd7f260-5c55-49ff-828b-afd16ce678f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median execution time for 50% per-feat.cov. threshold: 44.6449 seconds\n",
      "Median execution time for 75% per-feat.cov. threshold: 31.7567 seconds\n",
      "Median execution time for 90% per-feat.cov. threshold: 32.4744 seconds\n",
      "Median execution time for 100% per-feat.cov. threshold: 30.3925 seconds\n"
     ]
    }
   ],
   "source": [
    "# Median execution time for each per-feat.cov. threshold\n",
    "print(\"Median execution time for 50% per-feat.cov. threshold: {count} seconds\".format(count=round(median([median([x.exec_time for x in results_50_exec_thresh_50_005_list]),\n",
    "                                                                                                          median([x.exec_time for x in results_50_exec_thresh_50_010_list]),\n",
    "                                                                                                          median([x.exec_time for x in results_50_exec_thresh_50_025_list])]),4)))\n",
    "\n",
    "print(\"Median execution time for 75% per-feat.cov. threshold: {count} seconds\".format(count=round(median([median([x.exec_time for x in results_50_exec_thresh_75_005_list]),\n",
    "                                                                                                          median([x.exec_time for x in results_50_exec_thresh_75_010_list]),\n",
    "                                                                                                          median([x.exec_time for x in results_50_exec_thresh_75_025_list])]),4)))\n",
    "\n",
    "print(\"Median execution time for 90% per-feat.cov. threshold: {count} seconds\".format(count=round(median([median([x.exec_time for x in results_50_exec_thresh_90_005_list]),\n",
    "                                                                                                          median([x.exec_time for x in results_50_exec_thresh_90_010_list]),\n",
    "                                                                                                          median([x.exec_time for x in results_50_exec_thresh_90_025_list])]),4)))\n",
    "\n",
    "print(\"Median execution time for 100% per-feat.cov. threshold: {count} seconds\".format(count=round(median([median([x.exec_time for x in results_50_exec_thresh_100_005_list]),\n",
    "                                                                                                          median([x.exec_time for x in results_50_exec_thresh_100_010_list]),\n",
    "                                                                                                          median([x.exec_time for x in results_50_exec_thresh_100_025_list])]),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "4265ea4d-c6bd-4312-be96-7874bfada6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The execution time for MDR within 0.25 was: 8.0559 seconds\n",
      "The execution time for MDR within 0.10 was: 32.1155 seconds\n",
      "The execution time for MDR within 0.05 was: 85.9773 seconds\n"
     ]
    }
   ],
   "source": [
    "# Median execution time for each MDR range\n",
    "print(\"The execution time for MDR within 0.25 was: {count} seconds\".format(count=round(median([median([x.exec_time for x in results_50_exec_thresh_50_025_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_75_025_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_90_025_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_100_025_list])]), 4)))\n",
    "\n",
    "print(\"The execution time for MDR within 0.10 was: {count} seconds\".format(count=round(median([median([x.exec_time for x in results_50_exec_thresh_50_010_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_75_010_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_90_010_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_100_010_list])]), 4)))\n",
    "\n",
    "print(\"The execution time for MDR within 0.05 was: {count} seconds\".format(count=round(median([median([x.exec_time for x in results_50_exec_thresh_50_005_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_75_005_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_90_005_list]),\n",
    "                                                                                               median([x.exec_time for x in results_50_exec_thresh_100_005_list])]), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3f077-8f9a-4d3c-a976-cb48c91d9b62",
   "metadata": {},
   "source": [
    "#### Plot non-dominated solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.08",
   "language": "python",
   "name": "rapids-22.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
