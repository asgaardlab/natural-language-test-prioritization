{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e81441-b536-44f8-b933-9456266c5d72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiments with zero-shot classification techniques to classify manual test cases (i.e., textual descriptions of test cases) into the game features that they cover.\n",
    "\n",
    "We experiment with the following models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f80a4bbb-97eb-4db0-894b-e90c855b5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import median, mean\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, Phrases, KeyedVectors\n",
    "import fasttext\n",
    "from scipy import spatial\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import multilabel_confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d917a7-6eb9-4b14-9069-935a8f535a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook configurations\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7893294e-870f-427d-a1ec-14189cb9de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules with different classification methods\n",
    "from zero_shot_nli import run_zero_shot_nli\n",
    "from zero_shot_nli_metrics_per_class import run_zero_shot_nli_metrics_per_class\n",
    "from zero_shot_latent_embedding import run_zero_shot_latent_emb\n",
    "from baseline import run_baseline\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775d9c5-b8af-4a8d-abdb-2287cdaf92e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50213011-9d3b-4e5d-9a64-ae32b284d764",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load and pre-process labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3f82b-ecb2-4d90-837d-90e83762012f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load labeled data\n",
    "labeled_test_cases_df = utils.read_data()\n",
    "labeled_test_cases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee51372-f123-4f71-9e06-bd7d35c06cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process data\n",
    "(test_case_name_df, test_case_name_obj_df) = utils.preprocess_data(labeled_test_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90708d71-6257-4bf3-b9c4-9ee13cae2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique labels (game features)\n",
    "unique_labels = []\n",
    "for index,row in test_case_name_df.iterrows():\n",
    "    labels = row['labels']\n",
    "    for lab in labels:\n",
    "        if lab not in unique_labels:\n",
    "            unique_labels.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef15c0-5702-47b0-8345-2a201e81ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict with counter of unique labels\n",
    "unique_labels_count = dict.fromkeys(unique_labels,0)\n",
    "for index,row in test_case_name_df.iterrows():\n",
    "    labels = row['labels']\n",
    "    for lab in labels:\n",
    "        unique_labels_count[lab] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf57646-84d3-4f95-ba1c-7bb379a358a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg number of unique labels\n",
    "mean_label_counter = mean(list(unique_labels_count.values()))\n",
    "print(\"There are on average {count} unique labels.\".format(count=mean_label_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dffdfe-c650-41d0-a244-b42cbe235c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels (game features)\n",
    "candidate_label_file = \"INSERT_DIR_OF_LIST_OF_GAME_FEATURES\"\n",
    "candidate_labels = candidate_label_file.read().splitlines()\n",
    "print(\"There are {count} candidate labels.\".format(count=len(candidate_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f0da06-0d8d-497b-95cd-48a0d4caa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Mlflow experiment dir\n",
    "experiment_dir = \"INSERT_DIR_TO_RECORD_EXPERIMENTS_WITH_MLFLOW\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73f4b9-8afb-4c40-8ecf-de9dad49ea5b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adb4b7-f6f1-4342-9a98-d34f5008d19b",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874384c-faf5-4938-9937-1779fa2c5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define name and description of experiment\n",
    "experiment_name = \"Baseline experiment - Test case name and objective\"\n",
    "experiment_active = mlflow.set_experiment(experiment_name)\n",
    "experiment_id = experiment_active.experiment_id\n",
    "MlflowClient().set_experiment_tag(experiment_id, \n",
    "     \"mlflow.note.content\",\"Evaluate keyword-based approach to classify test cases (with test case name and objective).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9677f1-0fea-4f5d-a1ec-93dbcc5839b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dash by space in candidate labels with more than one word (achieves better performance)\n",
    "candidate_labels_mod = []\n",
    "for elem in candidate_labels:\n",
    "    res = ' '.join(elem.split('-'))\n",
    "    candidate_labels_mod.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38186ee-7000-4a01-828c-2c9a71174693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases represented by name\n",
    "run_name = \"Test case name\"\n",
    "run_baseline(test_case_name_df, candidate_labels, candidate_labels_mod, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44960c69-46d8-4909-a0c4-aefddbe4efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases represented by name + objective\n",
    "run_name = \"Test case name + objective\"\n",
    "run_baseline(test_case_name_obj_df, candidate_labels, candidate_labels_mod, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0071a9f-882b-4799-b31a-750fd7d6e43a",
   "metadata": {},
   "source": [
    "### Experiments with individual zero-shot techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e96a0aa-98f4-47cf-84b6-71d8e59651b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### BartLargeMNLI - [facebook/bart-large-mnli](https://huggingface.co/facebook/bart-large-mnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd6817-a555-44e4-8f64-bdbaa83d68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define name and description of experiment\n",
    "experiment_name = \"BartLargeMNLI - Test case name and objective\"\n",
    "experiment_active = mlflow.set_experiment(experiment_name)\n",
    "experiment_id = experiment_active.experiment_id\n",
    "MlflowClient().set_experiment_tag(experiment_id, \n",
    "     \"mlflow.note.content\",\"Evaluate BartLargeMNLI to classify test cases (with test case name and objective).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ad8b0-af1a-4090-b9ce-941b9e62b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zero-shot classifier from the HF pipeline - set device=0 to use GPU for faster inference\n",
    "zero_shot_nli_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f92b9f-6713-4a98-a531-19d692581212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name\n",
    "run_name = \"Test case name\"\n",
    "run_zero_shot_nli(zero_shot_nli_classifier, candidate_labels, test_case_name_df, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af7ae7-ab8c-4795-a9c9-fc480d6c13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name + test case objective\n",
    "run_name = \"Test case name + objective\"\n",
    "run_zero_shot_nli(zero_shot_nli_classifier, candidate_labels, test_case_name_obj_df, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c6e593-8422-4eb6-af98-3fa90c37cf3a",
   "metadata": {},
   "source": [
    "#### CrossEncoderNLI - [cross-encoder/nli-distilroberta-base](https://huggingface.co/cross-encoder/nli-distilroberta-base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a916023-bbda-411e-be12-4b0e526590f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define name and description of experiment\n",
    "experiment_name = \"CrossEncoderNLI - Test case name and objective\"\n",
    "experiment_active = mlflow.set_experiment(experiment_name)\n",
    "experiment_id = experiment_active.experiment_id\n",
    "MlflowClient().set_experiment_tag(experiment_id, \n",
    "     \"mlflow.note.content\",\"Evaluate CrossEncoderNLI to classify test cases (with test case name and objective).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbcc9c-e878-4726-845e-68e12bbd06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zero-shot classifier from the HF pipeline - set device=0 to use GPU for faster inference\n",
    "zero_shot_nli_cross_enc_classifier = pipeline(\"zero-shot-classification\", model='cross-encoder/nli-distilroberta-base', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c98d49-20fb-41d9-8b97-45e92118a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name\n",
    "run_name = \"Test case name\"\n",
    "run_zero_shot_nli(zero_shot_nli_cross_enc_classifier, candidate_labels, test_case_name_df, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f438d39-0e63-4547-a688-92ddf6a8c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name + test case objective\n",
    "run_name = \"Test case name + objective\"\n",
    "run_zero_shot_nli(zero_shot_nli_cross_enc_classifier, candidate_labels, test_case_name_obj_df, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151992a1-dbe8-4aca-a35e-f5aca7bbf93d",
   "metadata": {},
   "source": [
    "#### LatentEmb - [latent-embeddings](https://joeddav.github.io/blog/2020/05/29/ZSL.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d32469-8ba9-43a5-83c1-1dd791fb26cf",
   "metadata": {},
   "source": [
    "We experiment with Wor2vec, Fasttext, and Glove embedding models together with the SBERT sentence embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682b582-c47a-4585-9014-f24c968ad56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define name and description of experiment\n",
    "experiment_name = \"Zero-shot Latent embeddings - Word embbeding models\"\n",
    "experiment_active = mlflow.set_experiment(experiment_name)\n",
    "experiment_id = experiment_active.experiment_id\n",
    "MlflowClient().set_experiment_tag(experiment_id, \n",
    "     \"mlflow.note.content\",\"Evaluate different word embedding models for zero-shot with latent embeddings approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe94b2-43d0-47f7-967a-4a3222d67665",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_name = 'sentence-t5-large'\n",
    "sbert_model = SentenceTransformer(sbert_name, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6b71c-2f5a-49e7-8f63-66e9e6d97584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinary_least_squares_lr(\n",
    "    X: torch.Tensor, Y: torch.Tensor, alpha: float = 0) -> torch.Tensor:\n",
    "    \"\"\"Computes ordinary least squares\n",
    "    For more information on the derivation of the closed-form expression,\n",
    "    check it the Wikipedia page here:\n",
    "    https://en.wikipedia.org/wiki/Ordinary_least_squares#Matrix/vector_formulation\n",
    "    In brief: we find a matrix, w, that transforms X to Y according to:\n",
    "    Y = Xw\n",
    "    (X.T X)^-1 X.T Y = [(X.T X)^-1 X.T X]w\n",
    "    w = (X.T X + alpha*I)^-1 X.T Y\n",
    "    where I is the identity matrix and alpha is the amount of regularization.\n",
    "    alpha = 0 is equivalent to OLS (ordinary least squares)\n",
    "    alpha >= 0 is ridge regression / l2 regularization\n",
    "    \"\"\"\n",
    "    X_norm = F.normalize(X, p=2, dim=1)\n",
    "    Y_norm = F.normalize(Y, p=2, dim=1)\n",
    "    I = torch.eye(X_norm.shape[1])\n",
    "\n",
    "    inner = torch.matmul(X_norm.T, X_norm) + alpha * I\n",
    "    # Z = torch.linalg.inv(inner)\n",
    "    Z = torch.inverse(inner)\n",
    "    Z = torch.matmul(Z, X_norm.T)\n",
    "    w = torch.matmul(Z, Y_norm)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4450b-3bb5-4e88-a2f4-bed33c3a2eb6",
   "metadata": {},
   "source": [
    "##### Zero-shot Latent embeddings - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718cd4b-59c1-4c48-82b2-63c8627da8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec pre-trained model\n",
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1d661-372c-4591-8d85-b0949632e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_words_pretrained = w2v_model.index_to_key[:20000]\n",
    "print(\"Len of topk word vector\", len(topk_words_pretrained))\n",
    "\n",
    "# Remove stopwords\n",
    "topk_words_pretrained = [x for x in topk_words_pretrained if x not in stopwords.words('english')]\n",
    "\n",
    "# Remove punctuations\n",
    "topk_words_pretrained = [x for x in topk_words_pretrained if ( (x not in string.punctuation) or (x[0] not in string.punctuation) )]\n",
    "\n",
    "# Remove single letters/digits\n",
    "topk_words_pretrained = [x for x in topk_words_pretrained if len(x) > 1]\n",
    "\n",
    "# Remove any remaining number\n",
    "topk_words_pretrained = [x for x in topk_words_pretrained if not x.isdigit()]\n",
    "\n",
    "print(\"Len of topk word vector after filtering\", len(topk_words_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758e49f-ff2f-4b9a-922b-ac723bc07277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get w2v embeddings\n",
    "w2v_emb_vectors = []\n",
    "for word in topk_words_pretrained:\n",
    "    w2v_emb_vectors.append(w2v_model.get_vector(word))\n",
    "    \n",
    "w2v_emb_vectors = np.array(w2v_emb_vectors)\n",
    "w2v_emb_vectors = torch.tensor(w2v_emb_vectors)\n",
    "print(\"Len of w2v embedding vector list\", len(w2v_emb_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0f370-afb0-4051-8492-c71eb6c3504b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get SBERT embeddings for the same set of words\n",
    "sbert_emb_vectors = []\n",
    "for word in topk_words_pretrained:\n",
    "    sbert_emb_vectors.append(sbert_model.encode(word))\n",
    "    \n",
    "sbert_emb_vectors = np.array(sbert_emb_vectors)\n",
    "sbert_emb_vectors = torch.tensor(sbert_emb_vectors)\n",
    "print(\"Len of sbert embedding vector list\", len(sbert_emb_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdbe95b-1c48-4dbc-97fb-ac7874972a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute transfer matrix\n",
    "transfer_matrix = ordinary_least_squares_lr(sbert_emb_vectors, w2v_emb_vectors, alpha=0)\n",
    "print(transfer_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f48636c-686d-4969-be56-ff2d384d9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings of candidate labels\n",
    "candidate_label_embeddings = sbert_model.encode(candidate_labels_mod)\n",
    "print(candidate_label_embeddings.shape)\n",
    "\n",
    "# Covert to tensor\n",
    "candidate_label_embeddings = torch.tensor(candidate_label_embeddings)\n",
    "print(candidate_label_embeddings.shape)\n",
    "\n",
    "# Apply linear transformation\n",
    "candidate_label_embeddings_transformed = torch.mm(candidate_label_embeddings, transfer_matrix)\n",
    "print(candidate_label_embeddings_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7a8e4-87c3-4f28-84f6-ea84118824cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name\n",
    "run_name = 'Test case name - ' + 'Word2Vec + ' + sbert_name\n",
    "run_zero_shot_latent_emb(test_case_name_df, candidate_labels_mod, candidate_label_embeddings_transformed,\n",
    "                         sbert_model, transfer_matrix, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cba818-71c3-4552-8f8b-7e0c52afb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name + test case objective\n",
    "run_name = 'Test case name + objective - ' + 'Word2Vec + ' + sbert_name\n",
    "run_zero_shot_latent_emb(test_case_name_obj_df, candidate_labels_mod, candidate_label_embeddings_transformed,\n",
    "                         sbert_model, transfer_matrix, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b654db0-1820-4d69-909d-b0ba859922de",
   "metadata": {},
   "source": [
    "##### Zero-shot Latent embeddings - Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fca459-b388-432b-86d3-af5aedc325c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "fasttext_model = fasttext.load_model(\"INSERT_PATH_OF_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e67616-096d-4da7-b604-482afb56229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_words_pretrained = fasttext_model.get_words()[:20000]\n",
    "print(\"Len of topk word vector\", len(topk_words_pretrained))\n",
    "\n",
    "# Remove stopwords\n",
    "topk_words_pretrained = [x for x in topk_words_pretrained if x not in stopwords.words('english')]\n",
    "\n",
    "# Remove punctuations\n",
    "topk_words_pretrained = [x for x in topk_words_pretrained if ( (x not in string.punctuation) or (x[0] not in string.punctuation) )]\n",
    "\n",
    "# Remove single letters/digits\n",
    "topk_words_pretrained = [x for x in topk_words_pretrained if len(x) > 1]\n",
    "\n",
    "# Remove any remaining number\n",
    "topk_words_pretrained = [x for x in topk_words_pretrained if not x.isdigit()]\n",
    "\n",
    "print(\"Len of topk word vector after filtering\", len(topk_words_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88564c-a4c6-410e-a457-3441cde21625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fasttext embeddings\n",
    "ft_emb_vectors = []\n",
    "for word in topk_words_pretrained:\n",
    "    ft_emb_vectors.append(fasttext_model.get_word_vector(word))\n",
    "    \n",
    "ft_emb_vectors = np.array(ft_emb_vectors)\n",
    "ft_emb_vectors = torch.tensor(ft_emb_vectors)\n",
    "print(\"Len of fasttext embedding vector list\", len(ft_emb_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb3d2f-73b0-4262-a659-7d44a6000e95",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get SBERT embeddings for the same set of words\n",
    "sbert_emb_vectors = []\n",
    "for word in topk_words_pretrained:\n",
    "    sbert_emb_vectors.append(sbert_model.encode(word))\n",
    "    \n",
    "sbert_emb_vectors = np.array(sbert_emb_vectors)\n",
    "sbert_emb_vectors = torch.tensor(sbert_emb_vectors)\n",
    "print(\"Len of sbert embedding vector list\", len(sbert_emb_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863359c-5eb8-409f-8e85-6d5e95b0a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute transfer matrix\n",
    "transfer_matrix = ordinary_least_squares_lr(sbert_emb_vectors, ft_emb_vectors, alpha=0)\n",
    "print(transfer_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7ca70-f415-42c5-b48b-45f6673ab589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings of candidate labels\n",
    "candidate_label_embeddings = sbert_model.encode(candidate_labels_mod)\n",
    "print(candidate_label_embeddings.shape)\n",
    "\n",
    "# Covert to tensor\n",
    "candidate_label_embeddings = torch.tensor(candidate_label_embeddings)\n",
    "print(candidate_label_embeddings.shape)\n",
    "\n",
    "# Apply linear transformation\n",
    "candidate_label_embeddings_transformed = torch.mm(candidate_label_embeddings, transfer_matrix)\n",
    "print(candidate_label_embeddings_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e5cac-3191-4daf-86fc-cddbf091bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name\n",
    "run_name = 'Test case name - ' + 'Fasttext + ' + sbert_name\n",
    "run_zero_shot_latent_emb(test_case_name_df, candidate_labels_mod, candidate_label_embeddings_transformed,\n",
    "                         sbert_model, transfer_matrix, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173b23f-cd78-48b3-8b20-50656aa1bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name + test case objective\n",
    "run_name = 'Test case name + objective - ' + 'Fasttext + ' + sbert_name\n",
    "run_zero_shot_latent_emb(test_case_name_obj_df, candidate_labels_mod, candidate_label_embeddings_transformed,\n",
    "                         sbert_model, transfer_matrix, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdde9c-195a-49fa-8e74-4439c7157791",
   "metadata": {},
   "source": [
    "##### Zero-shot Latent embeddings - Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7e0b9-f5bf-44f2-9235-6fe436c4cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with word embeddings from Glove\n",
    "embeddings_index = {}\n",
    "f = open('INSERT_PATH_OF_MODEL','r',encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    vector = np.asarray([float(val) for val in values[1:]])\n",
    "    embeddings_index[word] = vector\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f6050-dd2c-4bdd-baa0-7aa17232cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get glove embeddings (using the same 'topk_words_pretrained' as before since we cannot get word frequency from glove)\n",
    "glove_emb_vectors = []\n",
    "sbert_emb_vectors = []\n",
    "\n",
    "for word in topk_words_pretrained:\n",
    "    try:\n",
    "        glove_emb_vectors.append(embeddings_index[word])\n",
    "        sbert_emb_vectors.append(sbert_model.encode(word))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "glove_emb_vectors = np.array(glove_emb_vectors)\n",
    "glove_emb_vectors = torch.tensor(glove_emb_vectors)\n",
    "\n",
    "# Convert from float64 (double) to float\n",
    "glove_emb_vectors = glove_emb_vectors.type(torch.float32) \n",
    "print(\"Len of glove embedding vector list\", len(glove_emb_vectors))\n",
    "\n",
    "sbert_emb_vectors = np.array(sbert_emb_vectors)\n",
    "sbert_emb_vectors = torch.tensor(sbert_emb_vectors)\n",
    "print(\"Len of sbert embedding vector list\", len(sbert_emb_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5736e23-57b0-4bd7-9943-11b4c3e428de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute transfer matrix\n",
    "transfer_matrix = ordinary_least_squares_lr(sbert_emb_vectors, glove_emb_vectors, alpha=0)\n",
    "print(transfer_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a0216-2b0f-4508-954b-4f1f9c2cb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings of candidate labels\n",
    "candidate_label_embeddings = sbert_model.encode(candidate_labels_mod)\n",
    "print(candidate_label_embeddings.shape)\n",
    "\n",
    "# Covert to tensor\n",
    "candidate_label_embeddings = torch.tensor(candidate_label_embeddings)\n",
    "print(candidate_label_embeddings.shape)\n",
    "\n",
    "# Apply linear transformation\n",
    "candidate_label_embeddings_transformed = torch.mm(candidate_label_embeddings, transfer_matrix)\n",
    "print(candidate_label_embeddings_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd91ead-cad4-489e-b6a6-0c7092c6b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name\n",
    "run_name = 'Test case name - ' + 'Glove + ' + sbert_name\n",
    "run_zero_shot_latent_emb(test_case_name_df, candidate_labels_mod, candidate_label_embeddings_transformed,\n",
    "                         sbert_model, transfer_matrix, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e80dd-db6d-4917-918a-aa023e96a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier - considering test case as test case name + test case objective\n",
    "run_name = 'Test case name + objective - ' + 'Glove + ' + sbert_name\n",
    "run_zero_shot_latent_emb(test_case_name_obj_df, candidate_labels_mod, candidate_label_embeddings_transformed,\n",
    "                         sbert_model, transfer_matrix, experiment_name, run_name, experiment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc933f-ccb8-4f59-a6dc-31617fa769d5",
   "metadata": {},
   "source": [
    "### Experiments with **ensembles** of individual zero-shot techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c88cd7f-fd5d-47bb-a47c-4fbc7ec336e5",
   "metadata": {},
   "source": [
    "#### EnsMajorVoting - Ensemble with majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f97f6-9f84-4749-9e91-4c6eeb1f2af0",
   "metadata": {},
   "source": [
    "#### EnsFullInters - Ensemble with full intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc32164-351c-43a0-9ec4-3e28e5ca4dc2",
   "metadata": {},
   "source": [
    "#### EnsBackOffTwo - Ensemble with back-off using top-2 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b089eb2-ea66-422b-a2e0-c6eab58c2e90",
   "metadata": {},
   "source": [
    "#### EnsBackOffComplete - Ensemble with back-off using all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d218902-0aec-4940-9c08-dfb7513f2d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f49dd-196e-4db6-8151-bb11957e2f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57097e21-9720-4a78-ba25-8134e8f13e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58a3c0-cf1b-4fe3-b26a-f141f1e2481d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d901f-2be0-4086-8237-cd350e72eb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c3941-6fe8-445b-adc0-8dba12d4ae1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec395f3-fd20-4c48-aced-798fc2dde615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.08",
   "language": "python",
   "name": "rapids-22.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
